{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = pd.read_csv('../../amazon_review_polarity_data/train.csv',header=None)\n",
    "# smallset = raw.sample(360000)\n",
    "# smallset.to_csv('small_training_set.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('small_training_set.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['label','title','body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Frustrating</td>\n",
       "      <td>Breathnach's Simple Abundance and gratitude jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Not what I expected... But Good</td>\n",
       "      <td>I was looking for a battery grip extended batt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>well worth your money</td>\n",
       "      <td>After buying and using seveeral different and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Wake up sisters....</td>\n",
       "      <td>I read this book in one day. I Could not put i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Terrible help file</td>\n",
       "      <td>Was trying to use the alignment feature with t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                            title  \\\n",
       "0      1                      Frustrating   \n",
       "1      2  Not what I expected... But Good   \n",
       "2      2            well worth your money   \n",
       "3      2              Wake up sisters....   \n",
       "4      1               Terrible help file   \n",
       "\n",
       "                                                body  \n",
       "0  Breathnach's Simple Abundance and gratitude jo...  \n",
       "1  I was looking for a battery grip extended batt...  \n",
       "2  After buying and using seveeral different and ...  \n",
       "3  I read this book in one day. I Could not put i...  \n",
       "4  Was trying to use the alignment feature with t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359986, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer=WordNetLemmatizer()\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   Frustrating\n",
       "1               Not what I expected... But Good\n",
       "2                         well worth your money\n",
       "3                           Wake up sisters....\n",
       "4                            Terrible help file\n",
       "                          ...                  \n",
       "359995                      Not what I expected\n",
       "359996               Very average for the roots\n",
       "359997                     This movie sucks ***\n",
       "359998    Doesn't cover multi-carburetor tuning\n",
       "359999             You have got be kidding me!!\n",
       "Name: title, Length: 359986, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   frustrat\n",
       "1            not what i expected... but good\n",
       "2                      well worth your money\n",
       "3                        wake up sisters....\n",
       "4                          terrible help fil\n",
       "                         ...                \n",
       "359995                     not what i expect\n",
       "359996             very average for the root\n",
       "359997                  this movie sucks ***\n",
       "359998    doesn't cover multi-carburetor tun\n",
       "359999          you have got be kidding me!!\n",
       "Name: title, Length: 359986, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title.apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   Frustrating\n",
       "1               Not what I expected... But Good\n",
       "2                         well worth your money\n",
       "3                           Wake up sisters....\n",
       "4                            Terrible help file\n",
       "                          ...                  \n",
       "359995                      Not what I expected\n",
       "359996               Very average for the roots\n",
       "359997                     This movie sucks ***\n",
       "359998    Doesn't cover multi-carburetor tuning\n",
       "359999             You have got be kidding me!!\n",
       "Name: title, Length: 359986, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title.apply(lambda x: lemmer.lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the boy's cars are different color\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"the boy's cars are different colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the boy's cars are different colors\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer.lemmatize(\"the boy's cars are different colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:300000]\n",
    "y_train = data.label[:300000]\n",
    "X_test = data.title[300000:]\n",
    "y_test = data.label[300000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x53294 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 787149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7970193045043844\n",
      "AUC:  0.7970203504704927\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: ['worst' 'awful' 'disappointing' 'useless' 'horrible' 'terrible' 'junk'\n",
      " 'disappointment' 'poorly' 'waste']\n",
      "Largest Coefs: ['wonderful' 'amazing' 'delightful' 'fabulous' 'gem' 'fantastic'\n",
      " 'underrated' 'awesome' 'excellent' 'outstanding']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 2_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)\n",
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8101557029973661\n",
      "AUC:  0.8101488386305544\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: ['worst' 'disappointing' 'awful' 'horrible' 'terrible' 'useless'\n",
      " 'great works' 'junk' 'disappointment' 'poorly']\n",
      "Largest Coefs: ['terrific' 'gem' 'underrated' 'fantastic' 'doesn better' 'awesome'\n",
      " 'excellent' 'outstanding' 'won disappointed' 'better expected']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 3_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,3))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)\n",
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8101723735538292\n",
      "AUC:  0.8101655537711288\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: ['worst' 'disappointing' 'awful' 'horrible' 'great works' 'terrible'\n",
      " 'useless' 'junk' 'disappointment' 'poorly']\n",
      "Largest Coefs: ['fabulous' 'terrific' 'gem' 'fantastic' 'doesn better' 'awesome'\n",
      " 'outstanding' 'excellent' 'won disappointed' 'better expected']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=5,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x21639 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 870770 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(tfidf_train, y_train)\n",
    "pred = model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.804337678791718\n",
      "AUC:  0.8043503823220594\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.title = data.title.apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:300000]\n",
    "y_train = data.label[:300000]\n",
    "X_test = data.title[300000:]\n",
    "y_test = data.label[300000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)\n",
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.806621545027173\n",
      "AUC:  0.8066096753796753\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: ['worst' 'disappointing' 'garbag' 'awful' 'useless' 'horrible' 'horribl'\n",
      " 'terribl' 'terrible' 'junk']\n",
      "Largest Coefs: ['fantastic' 'bad al' 'outstand' 'awesom' 'better expect' 'excel'\n",
      " 'outstanding' 'awesome' 'excellent' 'doesn disappoint']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.title = data.title.apply(lambda x: lemmer.lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:300000]\n",
    "y_train = data.label[:300000]\n",
    "X_test = data.title[300000:]\n",
    "y_test = data.label[300000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)\n",
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8065715333577835\n",
      "AUC:  0.8065600635440578\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: ['worst' 'disappointing' 'garbag' 'useless' 'awful' 'horrible' 'horribl'\n",
      " 'terribl' 'terrible' 'junk']\n",
      "Largest Coefs: ['fantastic' 'bad al' 'outstand' 'awesom' 'better expect' 'excel'\n",
      " 'outstanding' 'awesome' 'excellent' 'doesn disappoint']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. convert to count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.body[:300000]\n",
    "y_train = data.label[:300000]\n",
    "X_test = data.body[300000:]\n",
    "y_test = data.label[300000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = count_train.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in count_vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book', 150511),\n",
       " ('like', 82239),\n",
       " ('just', 75500),\n",
       " ('good', 70632),\n",
       " ('great', 67033),\n",
       " ('read', 53866),\n",
       " ('time', 52967),\n",
       " ('really', 45310),\n",
       " ('movie', 45184),\n",
       " ('don', 43240),\n",
       " ('love', 34628),\n",
       " ('buy', 32808),\n",
       " ('use', 32474),\n",
       " ('cd', 31943),\n",
       " ('product', 31870),\n",
       " ('better', 31038),\n",
       " ('bought', 30587),\n",
       " ('work', 29816),\n",
       " ('did', 29472),\n",
       " ('new', 27912),\n",
       " ('way', 27874),\n",
       " ('story', 27694),\n",
       " ('album', 27326),\n",
       " ('best', 27256),\n",
       " ('little', 26854),\n",
       " ('ve', 26797),\n",
       " ('think', 26618),\n",
       " ('does', 26225),\n",
       " ('make', 25119),\n",
       " ('know', 25039),\n",
       " ('got', 24615),\n",
       " ('music', 24424),\n",
       " ('money', 23556),\n",
       " ('people', 22957),\n",
       " ('want', 22725),\n",
       " ('books', 22166),\n",
       " ('years', 21944),\n",
       " ('recommend', 21886),\n",
       " ('old', 21776),\n",
       " ('used', 20823),\n",
       " ('bad', 20578),\n",
       " ('didn', 19662),\n",
       " ('dvd', 19220),\n",
       " ('reading', 19208),\n",
       " ('say', 19152),\n",
       " ('game', 19064),\n",
       " ('quality', 18386),\n",
       " ('life', 18239),\n",
       " ('songs', 18065),\n",
       " ('thing', 17547),\n",
       " ('thought', 17408),\n",
       " ('doesn', 16341),\n",
       " ('easy', 16274),\n",
       " ('lot', 16019),\n",
       " ('amazon', 15871),\n",
       " ('long', 15828),\n",
       " ('going', 15473),\n",
       " ('year', 15466),\n",
       " ('film', 15450),\n",
       " ('sound', 15441),\n",
       " ('worth', 15288),\n",
       " ('price', 15284),\n",
       " ('hard', 15161),\n",
       " ('need', 14955),\n",
       " ('right', 14936),\n",
       " ('characters', 14860),\n",
       " ('looking', 14843),\n",
       " ('author', 14436),\n",
       " ('day', 14139),\n",
       " ('look', 14038),\n",
       " ('times', 13967),\n",
       " ('ll', 13800),\n",
       " ('works', 13783),\n",
       " ('set', 13763),\n",
       " ('different', 13722),\n",
       " ('real', 13576),\n",
       " ('makes', 13309),\n",
       " ('end', 13122),\n",
       " ('series', 12977),\n",
       " ('fan', 12645),\n",
       " ('purchased', 12622),\n",
       " ('written', 12571),\n",
       " ('nice', 12511),\n",
       " ('song', 12278),\n",
       " ('far', 12259),\n",
       " ('watch', 12142),\n",
       " ('using', 12045),\n",
       " ('sure', 11989),\n",
       " ('big', 11968),\n",
       " ('reviews', 11936),\n",
       " ('disappointed', 11919),\n",
       " ('feel', 11891),\n",
       " ('actually', 11720),\n",
       " ('come', 11565),\n",
       " ('play', 11544),\n",
       " ('waste', 11517),\n",
       " ('things', 11504),\n",
       " ('problem', 11303),\n",
       " ('away', 11234),\n",
       " ('bit', 11123),\n",
       " ('fun', 11087),\n",
       " ('pretty', 10933),\n",
       " ('version', 10827),\n",
       " ('excellent', 10823),\n",
       " ('try', 10734),\n",
       " ('interesting', 10522),\n",
       " ('world', 10490),\n",
       " ('came', 10441),\n",
       " ('small', 10364),\n",
       " ('tried', 10167),\n",
       " ('loved', 9927),\n",
       " ('said', 9716),\n",
       " ('quite', 9664),\n",
       " ('months', 9653),\n",
       " ('original', 9578),\n",
       " ('item', 9509),\n",
       " ('stars', 9463),\n",
       " ('enjoy', 9442),\n",
       " ('highly', 9420),\n",
       " ('getting', 9240),\n",
       " ('having', 9178),\n",
       " ('help', 9149),\n",
       " ('seen', 9119),\n",
       " ('instead', 9092),\n",
       " ('purchase', 9041),\n",
       " ('high', 9015),\n",
       " ('video', 8991),\n",
       " ('writing', 8934),\n",
       " ('second', 8913),\n",
       " ('plot', 8885),\n",
       " ('wonderful', 8839),\n",
       " ('wanted', 8790),\n",
       " ('trying', 8697),\n",
       " ('days', 8688),\n",
       " ('10', 8653),\n",
       " ('information', 8624),\n",
       " ('review', 8552),\n",
       " ('maybe', 8552),\n",
       " ('probably', 8548),\n",
       " ('fine', 8538),\n",
       " ('believe', 8529),\n",
       " ('won', 8460),\n",
       " ('buying', 8439),\n",
       " ('isn', 8412),\n",
       " ('let', 8403),\n",
       " ('man', 8396),\n",
       " ('movies', 8325),\n",
       " ('received', 8267),\n",
       " ('heard', 8227),\n",
       " ('able', 8216),\n",
       " ('ago', 8168),\n",
       " ('perfect', 8137),\n",
       " ('favorite', 8067),\n",
       " ('band', 8058),\n",
       " ('character', 8048),\n",
       " ('star', 8037),\n",
       " ('live', 8031),\n",
       " ('box', 8000),\n",
       " ('worked', 7995),\n",
       " ('ordered', 7919),\n",
       " ('took', 7900),\n",
       " ('fact', 7831),\n",
       " ('couldn', 7791),\n",
       " ('true', 7786),\n",
       " ('definitely', 7783),\n",
       " ('listen', 7722),\n",
       " ('especially', 7674),\n",
       " ('order', 7668),\n",
       " ('light', 7652),\n",
       " ('went', 7647),\n",
       " ('home', 7609),\n",
       " ('enjoyed', 7602),\n",
       " ('point', 7565),\n",
       " ('understand', 7513),\n",
       " ('family', 7512),\n",
       " ('happy', 7500),\n",
       " ('wrong', 7500),\n",
       " ('job', 7483),\n",
       " ('wish', 7454),\n",
       " ('place', 7432),\n",
       " ('case', 7407),\n",
       " ('boring', 7399),\n",
       " ('cover', 7398),\n",
       " ('fit', 7386),\n",
       " ('short', 7385),\n",
       " ('water', 7338),\n",
       " ('started', 7330),\n",
       " ('comes', 7275),\n",
       " ('looks', 7270),\n",
       " ('minutes', 7229),\n",
       " ('gave', 7190),\n",
       " ('wasn', 7186),\n",
       " ('pages', 7172),\n",
       " ('kids', 7164),\n",
       " ('novel', 7150),\n",
       " ('poor', 7073),\n",
       " ('saw', 7055),\n",
       " ('gets', 6991),\n",
       " ('half', 6991),\n",
       " ('kind', 6952),\n",
       " ('line', 6947),\n",
       " ('unit', 6929),\n",
       " ('left', 6928),\n",
       " ('history', 6915),\n",
       " ('style', 6894),\n",
       " ('return', 6884),\n",
       " ('worst', 6874),\n",
       " ('start', 6870),\n",
       " ('son', 6851),\n",
       " ('stuff', 6803),\n",
       " ('making', 6801),\n",
       " ('liked', 6797),\n",
       " ('problems', 6779),\n",
       " ('funny', 6712),\n",
       " ('tell', 6703),\n",
       " ('children', 6682),\n",
       " ('collection', 6675),\n",
       " ('piece', 6664),\n",
       " ('overall', 6655),\n",
       " ('working', 6649),\n",
       " ('hope', 6619),\n",
       " ('couple', 6575),\n",
       " ('reason', 6486),\n",
       " ('size', 6478),\n",
       " ('picture', 6438),\n",
       " ('hear', 6432),\n",
       " ('amazing', 6389),\n",
       " ('beautiful', 6309),\n",
       " ('voice', 6260),\n",
       " ('cheap', 6186),\n",
       " ('simply', 6169),\n",
       " ('person', 6159),\n",
       " ('daughter', 6141),\n",
       " ('stories', 6126),\n",
       " ('rock', 6075),\n",
       " ('save', 6000),\n",
       " ('completely', 5993),\n",
       " ('tv', 5945),\n",
       " ('takes', 5944),\n",
       " ('sounds', 5917),\n",
       " ('page', 5863),\n",
       " ('mind', 5823),\n",
       " ('player', 5822),\n",
       " ('black', 5801),\n",
       " ('plastic', 5789),\n",
       " ('watching', 5734),\n",
       " ('battery', 5715),\n",
       " ('camera', 5715),\n",
       " ('finally', 5715),\n",
       " ('power', 5707),\n",
       " ('christmas', 5653),\n",
       " ('phone', 5653),\n",
       " ('friends', 5635),\n",
       " ('fast', 5623),\n",
       " ('experience', 5615),\n",
       " ('reader', 5614),\n",
       " ('idea', 5603),\n",
       " ('wouldn', 5590),\n",
       " ('simple', 5584),\n",
       " ('ok', 5573),\n",
       " ('company', 5564),\n",
       " ('goes', 5564),\n",
       " ('felt', 5550),\n",
       " ('gift', 5547),\n",
       " ('playing', 5539),\n",
       " ('easily', 5534),\n",
       " ('shows', 5529),\n",
       " ('wait', 5496),\n",
       " ('night', 5483),\n",
       " ('hours', 5477),\n",
       " ('child', 5441),\n",
       " ('house', 5434),\n",
       " ('young', 5427),\n",
       " ('learn', 5426),\n",
       " ('rest', 5411),\n",
       " ('needed', 5410),\n",
       " ('absolutely', 5365),\n",
       " ('difficult', 5347),\n",
       " ('today', 5345),\n",
       " ('guess', 5336),\n",
       " ('called', 5300),\n",
       " ('course', 5291),\n",
       " ('turn', 5290),\n",
       " ('copy', 5289),\n",
       " ('lost', 5268),\n",
       " ('school', 5255),\n",
       " ('fans', 5246),\n",
       " ('loves', 5240),\n",
       " ('store', 5232),\n",
       " ('truly', 5231),\n",
       " ('hold', 5225),\n",
       " ('computer', 5211),\n",
       " ('doing', 5186),\n",
       " ('words', 5185),\n",
       " ('past', 5178),\n",
       " ('ones', 5175),\n",
       " ('classic', 5174),\n",
       " ('weeks', 5161),\n",
       " ('track', 5143),\n",
       " ('thinking', 5110),\n",
       " ('given', 5108),\n",
       " ('title', 5104),\n",
       " ('action', 5100),\n",
       " ('unfortunately', 5059),\n",
       " ('terrible', 5058),\n",
       " ('service', 5054),\n",
       " ('god', 5047),\n",
       " ('write', 5038),\n",
       " ('gives', 5035),\n",
       " ('expected', 5024),\n",
       " ('low', 5018),\n",
       " ('says', 5013),\n",
       " ('recommended', 5003),\n",
       " ('week', 4991),\n",
       " ('baby', 4981),\n",
       " ('month', 4953),\n",
       " ('free', 4942),\n",
       " ('played', 4925),\n",
       " ('mr', 4902),\n",
       " ('friend', 4899),\n",
       " ('type', 4890),\n",
       " ('later', 4886),\n",
       " ('clear', 4855),\n",
       " ('needs', 4845),\n",
       " ('material', 4833),\n",
       " ('support', 4826),\n",
       " ('20', 4825),\n",
       " ('main', 4816),\n",
       " ('extremely', 4812),\n",
       " ('hand', 4790),\n",
       " ('horrible', 4789),\n",
       " ('head', 4780),\n",
       " ('longer', 4772),\n",
       " ('pictures', 4757),\n",
       " ('car', 4742),\n",
       " ('stay', 4739),\n",
       " ('complete', 4738),\n",
       " ('pay', 4732),\n",
       " ('told', 4721),\n",
       " ('tracks', 4711),\n",
       " ('entire', 4703),\n",
       " ('care', 4686),\n",
       " ('parts', 4666),\n",
       " ('toy', 4642),\n",
       " ('based', 4639),\n",
       " ('single', 4624),\n",
       " ('cool', 4609),\n",
       " ('release', 4584),\n",
       " ('yes', 4567),\n",
       " ('change', 4556),\n",
       " ('sense', 4554),\n",
       " ('acting', 4552),\n",
       " ('run', 4543),\n",
       " ('cut', 4530),\n",
       " ('awesome', 4527),\n",
       " ('guy', 4525),\n",
       " ('quickly', 4513),\n",
       " ('listening', 4477),\n",
       " ('expect', 4449),\n",
       " ('deal', 4445),\n",
       " ('dont', 4415),\n",
       " ('american', 4413),\n",
       " ('ending', 4412),\n",
       " ('color', 4409),\n",
       " ('special', 4403),\n",
       " ('hair', 4396),\n",
       " ('close', 4395),\n",
       " ('open', 4392),\n",
       " ('decided', 4388),\n",
       " ('disc', 4379),\n",
       " ('kept', 4356),\n",
       " ('stop', 4348),\n",
       " ('haven', 4344),\n",
       " ('albums', 4339),\n",
       " ('girl', 4332),\n",
       " ('season', 4331),\n",
       " ('clean', 4314),\n",
       " ('large', 4310),\n",
       " ('totally', 4307),\n",
       " ('machine', 4297),\n",
       " ('looked', 4279),\n",
       " ('available', 4277),\n",
       " ('unless', 4273),\n",
       " ('products', 4259),\n",
       " ('room', 4255),\n",
       " ('games', 4240),\n",
       " ('white', 4217),\n",
       " ('coffee', 4210),\n",
       " ('arrived', 4175),\n",
       " ('sent', 4163),\n",
       " ('husband', 4158),\n",
       " ('hot', 4151),\n",
       " ('huge', 4151),\n",
       " ('shipping', 4147),\n",
       " ('interested', 4142),\n",
       " ('follow', 4141),\n",
       " ('screen', 4140),\n",
       " ('self', 4134),\n",
       " ('check', 4124),\n",
       " ('design', 4122),\n",
       " ('matter', 4122),\n",
       " ('women', 4111),\n",
       " ('cost', 4109),\n",
       " ('level', 4107),\n",
       " ('inside', 4103),\n",
       " ('brand', 4096),\n",
       " ('broke', 4075),\n",
       " ('metal', 4058),\n",
       " ('sorry', 4046),\n",
       " ('30', 4040),\n",
       " ('slow', 4037),\n",
       " ('heart', 4015),\n",
       " ('number', 4013),\n",
       " ('finish', 4001),\n",
       " ('glad', 3992),\n",
       " ('scenes', 3985),\n",
       " ('heavy', 3983),\n",
       " ('lots', 3977),\n",
       " ('word', 3973),\n",
       " ('plus', 3933),\n",
       " ('remember', 3912),\n",
       " ('returned', 3908),\n",
       " ('exactly', 3907),\n",
       " ('dog', 3899),\n",
       " ('woman', 3895),\n",
       " ('add', 3889),\n",
       " ('replacement', 3884),\n",
       " ('mean', 3882),\n",
       " ('forward', 3870),\n",
       " ('software', 3846),\n",
       " ('previous', 3844),\n",
       " ('soon', 3840),\n",
       " ('war', 3836),\n",
       " ('opinion', 3832),\n",
       " ('non', 3807),\n",
       " ('lyrics', 3788),\n",
       " ('pop', 3786),\n",
       " ('strong', 3763),\n",
       " ('thank', 3732),\n",
       " ('stand', 3727),\n",
       " ('age', 3727),\n",
       " ('pick', 3721),\n",
       " ('early', 3721),\n",
       " ('useful', 3681),\n",
       " ('certainly', 3680),\n",
       " ('wife', 3672),\n",
       " ('customer', 3654),\n",
       " ('guys', 3652),\n",
       " ('extra', 3650),\n",
       " ('turned', 3635),\n",
       " ('class', 3633),\n",
       " ('taking', 3629),\n",
       " ('spend', 3623),\n",
       " ('text', 3573),\n",
       " ('radio', 3559),\n",
       " ('expensive', 3556),\n",
       " ('record', 3542),\n",
       " ('usually', 3538),\n",
       " ('john', 3516),\n",
       " ('beginning', 3515),\n",
       " ('bag', 3502),\n",
       " ('edition', 3489),\n",
       " ('boy', 3483),\n",
       " ('card', 3481),\n",
       " ('hit', 3478),\n",
       " ('worse', 3475),\n",
       " ('important', 3475),\n",
       " ('batteries', 3470),\n",
       " ('watched', 3460),\n",
       " ('model', 3446),\n",
       " ('coming', 3424),\n",
       " ('happened', 3418),\n",
       " ('face', 3418),\n",
       " ('guide', 3412),\n",
       " ('stick', 3410),\n",
       " ('leave', 3409),\n",
       " ('pieces', 3408),\n",
       " ('15', 3400),\n",
       " ('thanks', 3399),\n",
       " ('paid', 3398),\n",
       " ('chapter', 3385),\n",
       " ('knew', 3380),\n",
       " ('spent', 3377),\n",
       " ('oh', 3376),\n",
       " ('description', 3364),\n",
       " ('paper', 3361),\n",
       " ('helpful', 3359),\n",
       " ('recording', 3356),\n",
       " ('stopped', 3355),\n",
       " ('features', 3354),\n",
       " ('supposed', 3350),\n",
       " ('poorly', 3349),\n",
       " ('food', 3336),\n",
       " ('agree', 3335),\n",
       " ('guitar', 3332),\n",
       " ('entertaining', 3326),\n",
       " ('12', 3323),\n",
       " ('english', 3321),\n",
       " ('dark', 3320),\n",
       " ('example', 3311),\n",
       " ('cable', 3303),\n",
       " ('writer', 3297),\n",
       " ('performance', 3281),\n",
       " ('quick', 3276),\n",
       " ('50', 3263),\n",
       " ('hate', 3241),\n",
       " ('subject', 3237),\n",
       " ('awful', 3233),\n",
       " ('missing', 3227),\n",
       " ('country', 3198),\n",
       " ('issues', 3197),\n",
       " ('business', 3195),\n",
       " ('dead', 3188),\n",
       " ('replace', 3177),\n",
       " ('language', 3177),\n",
       " ('group', 3174),\n",
       " ('included', 3171),\n",
       " ('view', 3170),\n",
       " ('volume', 3169),\n",
       " ('ideas', 3163),\n",
       " ('sad', 3157),\n",
       " ('value', 3156),\n",
       " ('basic', 3143),\n",
       " ('older', 3129),\n",
       " ('art', 3126),\n",
       " ('tape', 3119),\n",
       " ('personal', 3114),\n",
       " ('fantastic', 3111),\n",
       " ('disappointing', 3101),\n",
       " ('seller', 3098),\n",
       " ('giving', 3095),\n",
       " ('authors', 3076),\n",
       " ('mother', 3062),\n",
       " ('program', 3061),\n",
       " ('wants', 3061),\n",
       " ('hoping', 3055),\n",
       " ('known', 3046),\n",
       " ('stupid', 3036),\n",
       " ('future', 3030),\n",
       " ('100', 3029),\n",
       " ('drive', 3026),\n",
       " ('hour', 3021),\n",
       " ('scene', 3015),\n",
       " ('gone', 3013),\n",
       " ('released', 3012),\n",
       " ('control', 3003),\n",
       " ('recently', 2998),\n",
       " ('films', 2996),\n",
       " ('print', 2993),\n",
       " ('annoying', 2988),\n",
       " ('feeling', 2988),\n",
       " ('disappointment', 2981),\n",
       " ('instructions', 2980),\n",
       " ('handle', 2977),\n",
       " ('fall', 2974),\n",
       " ('middle', 2973),\n",
       " ('issue', 2965),\n",
       " ('decent', 2962),\n",
       " ('seeing', 2961),\n",
       " ('keeps', 2955),\n",
       " ('taken', 2941),\n",
       " ('send', 2941),\n",
       " ('air', 2939),\n",
       " ('men', 2936),\n",
       " ('local', 2935),\n",
       " ('space', 2929),\n",
       " ('waiting', 2925),\n",
       " ('fiction', 2918),\n",
       " ('broken', 2918),\n",
       " ('uses', 2911),\n",
       " ('similar', 2910),\n",
       " ('hands', 2909),\n",
       " ('twice', 2905),\n",
       " ('saying', 2904),\n",
       " ('list', 2892),\n",
       " ('greatest', 2885),\n",
       " ('aren', 2882),\n",
       " ('major', 2881),\n",
       " ('including', 2873),\n",
       " ('ended', 2870),\n",
       " ('library', 2869),\n",
       " ('useless', 2866),\n",
       " ('wonder', 2865),\n",
       " ('weight', 2861),\n",
       " ('death', 2858),\n",
       " ('taste', 2846),\n",
       " ('break', 2837),\n",
       " ('com', 2832),\n",
       " ('advice', 2825),\n",
       " ('running', 2819),\n",
       " ('junk', 2811),\n",
       " ('online', 2805),\n",
       " ('red', 2803),\n",
       " ('humor', 2797),\n",
       " ('attention', 2783),\n",
       " ('lives', 2782),\n",
       " ('total', 2775),\n",
       " ('suggest', 2759),\n",
       " ('comfortable', 2755),\n",
       " ('body', 2751),\n",
       " ('cast', 2750),\n",
       " ('apart', 2744),\n",
       " ('figure', 2743),\n",
       " ('excited', 2738),\n",
       " ('pleased', 2737),\n",
       " ('tool', 2732),\n",
       " ('blue', 2728),\n",
       " ('reviewers', 2720),\n",
       " ('perfectly', 2715),\n",
       " ('human', 2693),\n",
       " ('package', 2688),\n",
       " ('finished', 2686),\n",
       " ('research', 2686),\n",
       " ('surprised', 2663),\n",
       " ('chance', 2660),\n",
       " ('okay', 2645),\n",
       " ('happen', 2640),\n",
       " ('loud', 2638),\n",
       " ('expecting', 2637),\n",
       " ('lack', 2637),\n",
       " ('actual', 2635),\n",
       " ('production', 2630),\n",
       " ('audio', 2623),\n",
       " ('enjoyable', 2618),\n",
       " ('clearly', 2617),\n",
       " ('area', 2606),\n",
       " ('wear', 2604),\n",
       " ('ms', 2600),\n",
       " ('cute', 2598),\n",
       " ('condition', 2597),\n",
       " ('wrote', 2588),\n",
       " ('readers', 2586),\n",
       " ('living', 2581),\n",
       " ('setting', 2581),\n",
       " ('device', 2580),\n",
       " ('modern', 2572),\n",
       " ('basically', 2571),\n",
       " ('learning', 2559),\n",
       " ('alot', 2557),\n",
       " ('questions', 2549),\n",
       " ('super', 2548),\n",
       " ('charge', 2545),\n",
       " ('step', 2543),\n",
       " ('knows', 2542),\n",
       " ('avoid', 2540),\n",
       " ('beat', 2539),\n",
       " ('sex', 2537),\n",
       " ('effort', 2530),\n",
       " ('dry', 2524),\n",
       " ('weak', 2517),\n",
       " ('sort', 2513),\n",
       " ('parents', 2513),\n",
       " ('means', 2511),\n",
       " ('solid', 2511),\n",
       " ('rate', 2505),\n",
       " ('possible', 2498),\n",
       " ('eyes', 2494),\n",
       " ('addition', 2485),\n",
       " ('singing', 2481),\n",
       " ('fell', 2481),\n",
       " ('message', 2477),\n",
       " ('garbage', 2472),\n",
       " ('date', 2470),\n",
       " ('graphics', 2465),\n",
       " ('obviously', 2462),\n",
       " ('regular', 2457),\n",
       " ('deep', 2456),\n",
       " ('trouble', 2455),\n",
       " ('mystery', 2450),\n",
       " ('details', 2450),\n",
       " ('nearly', 2439),\n",
       " ('noise', 2439),\n",
       " ('changed', 2437),\n",
       " ('feature', 2432),\n",
       " ('bring', 2432),\n",
       " ('content', 2430),\n",
       " ('refund', 2430),\n",
       " ('kid', 2429),\n",
       " ('musical', 2428),\n",
       " ('talk', 2428),\n",
       " ('actors', 2421),\n",
       " ('straight', 2420),\n",
       " ('seat', 2419),\n",
       " ('ray', 2417),\n",
       " ('general', 2408),\n",
       " ('mix', 2407),\n",
       " ('picked', 2390),\n",
       " ('talking', 2388),\n",
       " ('purchasing', 2387),\n",
       " ('learned', 2385),\n",
       " ('talent', 2381),\n",
       " ('moving', 2379),\n",
       " ('plan', 2378),\n",
       " ('effects', 2376),\n",
       " ('immediately', 2372),\n",
       " ('plays', 2369),\n",
       " ('horror', 2368),\n",
       " ('standard', 2358),\n",
       " ('background', 2358),\n",
       " ('somewhat', 2353),\n",
       " ('reference', 2351),\n",
       " ('rating', 2347),\n",
       " ('impossible', 2346),\n",
       " ('outside', 2340),\n",
       " ('putting', 2340),\n",
       " ('stuck', 2340),\n",
       " ('unique', 2339),\n",
       " ('note', 2333),\n",
       " ('covers', 2329),\n",
       " ('difference', 2328),\n",
       " ('compared', 2327),\n",
       " ('choice', 2325),\n",
       " ('present', 2315),\n",
       " ('late', 2315),\n",
       " ('king', 2314),\n",
       " ('sell', 2312),\n",
       " ('depth', 2312),\n",
       " ('chapters', 2311),\n",
       " ('miss', 2311),\n",
       " ('sony', 2308),\n",
       " ('soft', 2303),\n",
       " ('install', 2297),\n",
       " ('examples', 2297),\n",
       " ('fits', 2290),\n",
       " ('historical', 2289),\n",
       " ('filled', 2289),\n",
       " ('form', 2288),\n",
       " ('recipes', 2288),\n",
       " ('flat', 2283),\n",
       " ('romance', 2277),\n",
       " ('period', 2277),\n",
       " ('doubt', 2275),\n",
       " ('digital', 2275),\n",
       " ('shame', 2271),\n",
       " ('feels', 2267),\n",
       " ('likes', 2267),\n",
       " ('cause', 2267),\n",
       " ('novels', 2266),\n",
       " ('turns', 2265),\n",
       " ('feet', 2265),\n",
       " ('touch', 2257),\n",
       " ('pain', 2257),\n",
       " ('dance', 2255),\n",
       " ('girls', 2252),\n",
       " ('starts', 2244),\n",
       " ('bands', 2241),\n",
       " ('bible', 2230),\n",
       " ('impressed', 2230),\n",
       " ('reviewer', 2225),\n",
       " ('test', 2224),\n",
       " ('father', 2223),\n",
       " ('forget', 2222),\n",
       " ('trash', 2221),\n",
       " ('hits', 2219),\n",
       " ('particular', 2217),\n",
       " ('easier', 2216),\n",
       " ('windows', 2216),\n",
       " ('trip', 2215),\n",
       " ('contains', 2214),\n",
       " ('skin', 2213),\n",
       " ('provides', 2213),\n",
       " ('seriously', 2212),\n",
       " ('items', 2206),\n",
       " ('truth', 2202),\n",
       " ('button', 2196),\n",
       " ('science', 2196),\n",
       " ('crap', 2193),\n",
       " ('opened', 2189),\n",
       " ('results', 2182),\n",
       " ('mention', 2182),\n",
       " ('laugh', 2179),\n",
       " ('lead', 2177),\n",
       " ('market', 2173),\n",
       " ('various', 2168),\n",
       " ('warranty', 2166),\n",
       " ('section', 2153),\n",
       " ('points', 2152),\n",
       " ('lines', 2152),\n",
       " ('listened', 2147),\n",
       " ('vocals', 2146),\n",
       " ('sing', 2145),\n",
       " ('photos', 2145),\n",
       " ('imagine', 2138),\n",
       " ('negative', 2136),\n",
       " ('bother', 2135),\n",
       " ('episodes', 2134),\n",
       " ('site', 2133),\n",
       " ('range', 2126),\n",
       " ('printer', 2125),\n",
       " ('ways', 2123),\n",
       " ('correct', 2117),\n",
       " ('tells', 2116),\n",
       " ('near', 2114),\n",
       " ('anymore', 2112),\n",
       " ('brought', 2110),\n",
       " ('helped', 2109),\n",
       " ('understanding', 2106),\n",
       " ('consider', 2104),\n",
       " ('process', 2100),\n",
       " ('realize', 2098),\n",
       " ('sleep', 2090),\n",
       " ('wasted', 2088),\n",
       " ('despite', 2087),\n",
       " ('kindle', 2087),\n",
       " ('positive', 2087),\n",
       " ('owned', 2083),\n",
       " ('soul', 2082),\n",
       " ('comedy', 2078),\n",
       " ('leaves', 2075),\n",
       " ('ipod', 2073),\n",
       " ('powerful', 2072),\n",
       " ('table', 2071),\n",
       " ('minute', 2070),\n",
       " ('ask', 2070),\n",
       " ('soundtrack', 2063),\n",
       " ('cds', 2057),\n",
       " ('christian', 2057),\n",
       " ('mistake', 2057),\n",
       " ('fairly', 2056),\n",
       " ('smell', 2050),\n",
       " ('replaced', 2049),\n",
       " ('incredible', 2049),\n",
       " ('bottle', 2049),\n",
       " ('sit', 2046),\n",
       " ('students', 2040),\n",
       " ('died', 2039),\n",
       " ('happens', 2038),\n",
       " ('sweet', 2034),\n",
       " ('pass', 2028),\n",
       " ('web', 2027),\n",
       " ('wow', 2024),\n",
       " ('places', 2021),\n",
       " ('00', 2020),\n",
       " ('barely', 2016),\n",
       " ('returning', 2011),\n",
       " ('america', 2009),\n",
       " ('bed', 2007),\n",
       " ('dr', 2006),\n",
       " ('cat', 2005),\n",
       " ('la', 2003),\n",
       " ('internet', 2003),\n",
       " ('versions', 2003),\n",
       " ('helps', 2000),\n",
       " ('episode', 1999),\n",
       " ('pair', 1998),\n",
       " ('artist', 1997),\n",
       " ('manual', 1995),\n",
       " ('website', 1993),\n",
       " ('cup', 1990),\n",
       " ('failed', 1985),\n",
       " ('workout', 1985),\n",
       " ('filter', 1984),\n",
       " ('noticed', 1983),\n",
       " ('green', 1979),\n",
       " ('certain', 1979),\n",
       " ('exciting', 1974),\n",
       " ('skip', 1971),\n",
       " ('mentioned', 1970),\n",
       " ('study', 1967),\n",
       " ('cold', 1962),\n",
       " ('provide', 1960),\n",
       " ('normal', 1960),\n",
       " ('base', 1953),\n",
       " ('city', 1952),\n",
       " ('properly', 1952),\n",
       " ('wall', 1952),\n",
       " ('door', 1951),\n",
       " ('earlier', 1949),\n",
       " ('average', 1941),\n",
       " ('singer', 1938),\n",
       " ('boys', 1935),\n",
       " ('switch', 1934),\n",
       " ('plain', 1930),\n",
       " ('accurate', 1928),\n",
       " ('opening', 1925),\n",
       " ('40', 1924),\n",
       " ('throw', 1918),\n",
       " ('common', 1917),\n",
       " ('continue', 1915),\n",
       " ('added', 1915),\n",
       " ('attempt', 1912),\n",
       " ('described', 1905),\n",
       " ('sets', 1903),\n",
       " ('memory', 1900),\n",
       " ('appears', 1896),\n",
       " ('knowledge', 1893),\n",
       " ('advertised', 1890),\n",
       " ('11', 1889),\n",
       " ('mouse', 1886),\n",
       " ('include', 1884),\n",
       " ('tight', 1883),\n",
       " ('edge', 1882),\n",
       " ('particularly', 1880),\n",
       " ('80', 1878),\n",
       " ('cheaper', 1875),\n",
       " ('college', 1874),\n",
       " ('ready', 1872),\n",
       " ('dvds', 1870),\n",
       " ('floor', 1867),\n",
       " ('luck', 1867),\n",
       " ('installed', 1866),\n",
       " ('jazz', 1863),\n",
       " ('state', 1862),\n",
       " ('development', 1856),\n",
       " ('appreciate', 1854),\n",
       " ('plenty', 1852),\n",
       " ('brilliant', 1852),\n",
       " ('starting', 1850),\n",
       " ('gotten', 1845),\n",
       " ('earth', 1844),\n",
       " ('pc', 1844),\n",
       " ('key', 1843),\n",
       " ('pull', 1843),\n",
       " ('ear', 1842),\n",
       " ('question', 1840),\n",
       " ('bass', 1840),\n",
       " ('pack', 1839),\n",
       " ('smaller', 1838),\n",
       " ('slightly', 1838),\n",
       " ('crazy', 1836),\n",
       " ('fix', 1830),\n",
       " ('headphones', 1827),\n",
       " ('warm', 1824),\n",
       " ('designed', 1821),\n",
       " ('heat', 1815),\n",
       " ('considering', 1815),\n",
       " ('events', 1814),\n",
       " ('dialogue', 1813),\n",
       " ('forever', 1813),\n",
       " ('obvious', 1811),\n",
       " ('larger', 1807),\n",
       " ('info', 1807),\n",
       " ('summer', 1804),\n",
       " ('brother', 1802),\n",
       " ('carry', 1800),\n",
       " ('kitchen', 1797),\n",
       " ('sturdy', 1797),\n",
       " ('ends', 1793),\n",
       " ('die', 1792),\n",
       " ('im', 1789),\n",
       " ('admit', 1788),\n",
       " ('built', 1788),\n",
       " ('facts', 1786),\n",
       " ('published', 1784),\n",
       " ('concert', 1781),\n",
       " ('sold', 1780),\n",
       " ('travel', 1777),\n",
       " ('professional', 1777),\n",
       " ('final', 1777),\n",
       " ('genre', 1773),\n",
       " ('office', 1770),\n",
       " ('offer', 1770),\n",
       " ('dull', 1766),\n",
       " ('morning', 1764),\n",
       " ('speed', 1761),\n",
       " ('shot', 1760),\n",
       " ('tired', 1760),\n",
       " ('hearing', 1759),\n",
       " ('hell', 1758),\n",
       " ('bunch', 1757),\n",
       " ('concept', 1756),\n",
       " ('constantly', 1751),\n",
       " ('format', 1750),\n",
       " ('packaging', 1750),\n",
       " ('purpose', 1747),\n",
       " ('artists', 1746),\n",
       " ('eye', 1743),\n",
       " ('party', 1737),\n",
       " ('shape', 1737),\n",
       " ('fantasy', 1737),\n",
       " ('fresh', 1737),\n",
       " ('current', 1736),\n",
       " ('tale', 1735),\n",
       " ('holds', 1735),\n",
       " ('eat', 1734),\n",
       " ('players', 1734),\n",
       " ('michael', 1732),\n",
       " ('finding', 1730),\n",
       " ('sister', 1727),\n",
       " ('unlike', 1727),\n",
       " ('role', 1727),\n",
       " ('create', 1723),\n",
       " ('result', 1722),\n",
       " ('lasted', 1717),\n",
       " ('adventure', 1717),\n",
       " ('usual', 1715),\n",
       " ('produced', 1711),\n",
       " ('ridiculous', 1707),\n",
       " ('plug', 1707),\n",
       " ('moves', 1702),\n",
       " ('beware', 1700),\n",
       " ('telling', 1697),\n",
       " ('ability', 1696),\n",
       " ('mom', 1694),\n",
       " ('insight', 1691),\n",
       " ('complaint', 1690),\n",
       " ('apparently', 1690),\n",
       " ('blu', 1690),\n",
       " ('personally', 1685),\n",
       " ('evil', 1678),\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model creating, training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nb_classifier.predict(count_test)\n",
    "score = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192911679391858"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149781., 150219.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.22789527,  -9.47230164, -14.10703063, ..., -14.3947127 ,\n",
       "        -15.49332499, -15.49332499],\n",
       "       [ -9.05581721,  -9.61924092, -13.04142857, ..., -14.05302949,\n",
       "        -14.74617667, -14.74617667]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book' 'just' 'like' 'good' 'time' 'don' 'movie' 'read' 'really'\n",
      " 'product' 'buy' 'money' 'did' 'better' 'bought' 'work' 'great' 'use'\n",
      " 'bad' 'does']\n",
      "['book' 'great' 'good' 'like' 'just' 'read' 'love' 'time' 'really' 'movie'\n",
      " 'best' 'cd' 'album' 'use' 'story' 'don' 'little' 'music' 've' 'new']\n"
     ]
    }
   ],
   "source": [
    "neg_class_prob_sorted = nb_classifier.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = nb_classifier.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print(np.take(count_vectorizer.get_feature_names(), neg_class_prob_sorted[:20]))\n",
    "print(np.take(count_vectorizer.get_feature_names(), pos_class_prob_sorted[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28339, 102082, 109698, ...,  66345, 147578, 210062], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.feature_log_prob_[0, :].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.22789527,  -9.47230164, -14.10703063, ..., -14.3947127 ,\n",
       "       -15.49332499, -15.49332499])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.feature_log_prob_[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tf-tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x12549 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 726559 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(tfidf_train, y_train)\n",
    "pred = model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7947854499383189\n",
      "AUC:  0.7948052444564214\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = tfidf_train.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in tfidf_vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x210063 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8806272 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
