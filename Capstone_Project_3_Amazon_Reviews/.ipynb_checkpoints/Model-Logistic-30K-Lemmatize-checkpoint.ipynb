{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, precision_recall_fscore_support\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import time\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = pd.read_csv('../../amazon_review_polarity_data/train.csv',header=None)\n",
    "# smallset = raw.sample(360000)\n",
    "# smallset.to_csv('small_training_set.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('small_training_set_30k.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['label','title','body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Awesome show. Great shipping.</td>\n",
       "      <td>Two Parts to my review.The TV SHOW First..... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best films I've ever seen</td>\n",
       "      <td>It is as light and fun as a \"let's change the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Horribly flat and under developed</td>\n",
       "      <td>I ruined my vacation read (to Italy, none the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The Definitive Brisson</td>\n",
       "      <td>\"Robert Bresson: A Spiritual Style in Film\" by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Classic Motown Tech.</td>\n",
       "      <td>This a slamming yet funky set of 80's electro ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                 title  \\\n",
       "0      2         Awesome show. Great shipping.   \n",
       "1      2  One of the best films I've ever seen   \n",
       "2      1     Horribly flat and under developed   \n",
       "3      2                The Definitive Brisson   \n",
       "4      2                  Classic Motown Tech.   \n",
       "\n",
       "                                                body  \n",
       "0  Two Parts to my review.The TV SHOW First..... ...  \n",
       "1  It is as light and fun as a \"let's change the ...  \n",
       "2  I ruined my vacation read (to Italy, none the ...  \n",
       "3  \"Robert Bresson: A Spiritual Style in Film\" by...  \n",
       "4  This a slamming yet funky set of 80's electro ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:20000]\n",
    "y_train = data.label[:20000]\n",
    "X_test = data.title[20000:]\n",
    "y_test = data.label[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x11775 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 52724 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.01299142837524414 seconds ---\n",
      "accuracy:  0.7620762076207621\n",
      "AUC:  0.7615496420258778\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.5496516227722168 seconds ---\n",
      "accuracy:  0.7591759175917592\n",
      "AUC:  0.7594351479251585\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 46.14600992202759 seconds ---\n",
      "accuracy:  0.7434743474347435\n",
      "AUC:  0.7437197178460493\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Keep all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x12033 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 80968 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.011996030807495117 seconds ---\n",
      "accuracy:  0.7932793279327933\n",
      "AUC:  0.793125008252631\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.5570240020751953 seconds ---\n",
      "accuracy:  0.8023802380238024\n",
      "AUC:  0.8020754416507982\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.75369071960449 seconds ---\n",
      "accuracy:  0.7986798679867987\n",
      "AUC:  0.7985937917007941\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define min df, 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x6890 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 98435 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=3,ngram_range=(1,3))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.014990091323852539 seconds ---\n",
      "accuracy:  0.7998799879987999\n",
      "AUC:  0.7993949871218945\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.45305633544921875 seconds ---\n",
      "accuracy:  0.8056805680568057\n",
      "AUC:  0.8053074720220806\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.30671787261963 seconds ---\n",
      "accuracy:  0.7961796179617961\n",
      "AUC:  0.7963145850897265\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 tf-tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x6890 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 98435 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=3,ngram_range=(1,3))\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.010986328125 seconds ---\n",
      "accuracy:  0.7987798779877988\n",
      "AUC:  0.7983656189593243\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(tfidf_train, y_train)\n",
    "pred_1 = model_1.predict(tfidf_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.2836265563964844 seconds ---\n",
      "accuracy:  0.8071807180718071\n",
      "AUC:  0.8072908243147915\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(tfidf_train, y_train)\n",
    "pred_2 = model_2.predict(tfidf_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.346248865127563 seconds ---\n",
      "accuracy:  0.7933793379337933\n",
      "AUC:  0.7933504201139322\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(tfidf_train, y_train)\n",
    "pred_3 = model_3.predict(tfidf_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.body[:20000]\n",
    "y_train = data.label[:20000]\n",
    "X_test = data.body[20000:]\n",
    "y_test = data.label[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x48195 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 586790 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.028980255126953125 seconds ---\n",
      "accuracy:  0.8131813181318132\n",
      "AUC:  0.8134360634170174\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.146034002304077 seconds ---\n",
      "accuracy:  0.8287828782878288\n",
      "AUC:  0.8287472646279633\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 51.998783588409424 seconds ---\n",
      "accuracy:  0.8263826382638264\n",
      "AUC:  0.8264535934055778\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 no stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x48498 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1051428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.04297208786010742 seconds ---\n",
      "accuracy:  0.8176817681768177\n",
      "AUC:  0.8180646190005374\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.62457013130188 seconds ---\n",
      "accuracy:  0.8491849184918492\n",
      "AUC:  0.8491604523522099\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 49.96270418167114 seconds ---\n",
      "accuracy:  0.8266826682668267\n",
      "AUC:  0.8270207942292003\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 min df, ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x125847 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2203932 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=3,ngram_range=(1,3))\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.1435389518737793 seconds ---\n",
      "accuracy:  0.8661866186618662\n",
      "AUC:  0.8662579430322388\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10.883943319320679 seconds ---\n",
      "accuracy:  0.8744874487448745\n",
      "AUC:  0.8744409117626699\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 76.82256865501404 seconds ---\n",
      "accuracy:  0.8359835983598359\n",
      "AUC:  0.8362846675520156\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. tf-tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x125847 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2203932 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=3,ngram_range=(1,3))\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8667866786678667\n",
      "AUC:  0.8669954581520588\n"
     ]
    }
   ],
   "source": [
    "model_1 = MultinomialNB()\n",
    "model_1.fit(tfidf_train, y_train)\n",
    "pred_1 = model_1.predict(tfidf_test)\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8731873187318732\n",
      "AUC:  0.8733096311103979\n"
     ]
    }
   ],
   "source": [
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(tfidf_train, y_train)\n",
    "pred_2 = model_2.predict(tfidf_test)\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8344834483448345\n",
      "AUC:  0.8347810682045436\n"
     ]
    }
   ],
   "source": [
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(tfidf_train, y_train)\n",
    "pred_3 = model_3.predict(tfidf_test)\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Title + Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:20000]\n",
    "y_train = data.label[:20000]\n",
    "X_test = data[20000:]\n",
    "y_test = data.label[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x6890 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 98435 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=3,ngram_range=(1,3))\n",
    "count_train_title = count_vectorizer.fit_transform(X_train.title)\n",
    "count_test_title = count_vectorizer.transform(X_test.title)\n",
    "count_train_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x125847 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2203932 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=3,ngram_range=(1,3))\n",
    "count_train_body = count_vectorizer.fit_transform(X_train.body)\n",
    "count_test_body = count_vectorizer.transform(X_test.body)\n",
    "count_train_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x132737 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2302367 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train = hstack((count_train_title,count_train_body))\n",
    "count_test =  hstack((count_test_title,count_test_body))\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.25185656547546387 seconds ---\n",
      "accuracy:  0.8838883888388839\n",
      "AUC:  0.8839018479091134\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(count_train, y_train)\n",
    "pred_1 = model_1.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_1))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.08782696723938 seconds ---\n",
      "accuracy:  0.8953895389538954\n",
      "AUC:  0.8953901903926972\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "model_2.fit(count_train, y_train)\n",
    "pred_2 = model_2.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_2))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 84.34293007850647 seconds ---\n",
      "accuracy:  0.8565856585658566\n",
      "AUC:  0.8567888642899356\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(count_train, y_train)\n",
    "pred_3 = model_3.predict(count_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('accuracy: ' , accuracy_score(y_test, pred_3))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a quick practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Finaly, I'm so disappointed. It's disappointing.\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer.lemmatize(\"Finaly, I'm so disappointed. It's disappointing.\",'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"bought\",'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(['taking']), nltk.pos_tag(['disappointed']), nltk.pos_tag(['finaly']),nltk.pos_tag(['bought']),nltk.pos_tag(['wrote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n",
      "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "# 1. Init Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 2. Lemmatize Single Word with the appropriate POS tag\n",
    "word = 'feet'\n",
    "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
    "\n",
    "# 3. Lemmatize a Sentence with the appropriate POS tag\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])\n",
    "#> ['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Finaly', 'I', 'become', 'disappointed', 'at', 'him', '.', 'It', \"'s\", 'disappoint', '.', 'He', 'bought', 'car', 'quickly']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Finaly I became disappointed at him. It's disappointing. He bought cars quickly\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:1000].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50                                    Worst. Item. Ever.\n",
       "51                                              Twilight\n",
       "52                      Another love story gone wrong...\n",
       "53                        Some good laughs, but not many\n",
       "54                 Garmin Forerunner 350 Charging Cradle\n",
       "                             ...                        \n",
       "995                                          Bridge Book\n",
       "996                                            Too small\n",
       "997                                           Compelling\n",
       "998    Another first person account of life in the fa...\n",
       "999                       an inspiration to a new mother\n",
       "Name: title, Length: 950, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title[50:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426                   Not 32 oz . !\n",
       "671    ABSOULUTE GARBAGE HORRIBBILE\n",
       "289                    Good quality\n",
       "549                     Cool Device\n",
       "691    No eye irritation , high SPF\n",
       "579                   Inspirational\n",
       "647       Expo should be pay me ! !\n",
       "696             confidence reassure\n",
       "468            Completely worthless\n",
       "911        Just one minor criticism\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Awesome show. Great shipping.\n",
       "1    One of the best films I've ever seen\n",
       "2       Horribly flat and under developed\n",
       "3                  The Definitive Brisson\n",
       "4                    Classic Motown Tech.\n",
       "5             A surprising disappointment\n",
       "6                    A disgrace to Oneida\n",
       "7          This movie was poorly created.\n",
       "8                  Prophet Muhammad (saw)\n",
       "9                            great boots!\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [Awesome, show, ., Great, shipping, .]\n",
       "1    [One, of, the, best, film, I, 've, ever, see]\n",
       "2          [Horribly, flat, and, under, developed]\n",
       "3                       [The, Definitive, Brisson]\n",
       "4                       [Classic, Motown, Tech, .]\n",
       "5                  [A, surprising, disappointment]\n",
       "6                        [A, disgrace, to, Oneida]\n",
       "7             [This, movie, be, poorly, create, .]\n",
       "8                   [Prophet, Muhammad, (, saw, )]\n",
       "9                                 [great, boot, !]\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.title[:10].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:10].apply(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x36 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d71536cd678a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-d71536cd678a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-9a239ebfe8c6>\u001b[0m in \u001b[0;36mlemmatize_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-9a239ebfe8c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-1356c9f9ddbc>\u001b[0m in \u001b[0;36mget_wordnet_pos\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     tag_dict = {\"J\": wordnet.ADJ,\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m\"N\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             )\n\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data.title.apply(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.title[:20000]\n",
    "y_train = data.label[:20000]\n",
    "X_test = data.title[20000:]\n",
    "y_test = data.label[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2),min_df=3)\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(count_train, y_train)\n",
    "pred = model.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: ' , accuracy_score(y_test, pred))\n",
    "print(('AUC: '), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\n",
    "coef_index_sorted = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: {}'.format(feature_names[coef_index_sorted[:10]]))\n",
    "print('Largest Coefs: {}'.format(feature_names[coef_index_sorted[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = count_vectorizer.vocabulary_['dissapoint']\n",
    "count_train.sum(axis=0)[0,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
